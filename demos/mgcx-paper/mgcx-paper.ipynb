{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Demo: DCorr-X and MGC-X\n",
    "In this notebook, we demonstrate the cross-distance correlation (`DCorrX`) test and the multiscale graph correlation for time series (`MGCX`) test for independence of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from mgcpy.independence_tests.dcorrx import DCorrX\n",
    "from mgcpy.independence_tests.mgcx import MGCX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to compute and print DCorrX nd MGCX output values, given X and Y:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dcorrx(X, Y, max_lag):\n",
    "    dcorrx = DCorrX(max_lag = max_lag, which_test = 'unbiased')\n",
    "    dcorrx_statistic, metadata = dcorrx.test_statistic(X, Y)\n",
    "    p_value, _ = dcorrx.p_value(X, Y)\n",
    "    optimal_lag = metadata['optimal_lag']\n",
    "\n",
    "    print(\"DCorrX test statistic:\", dcorrx_statistic)\n",
    "    print(\"P Value:\", p_value)\n",
    "    print(\"Optimal Lag:\", optimal_lag)\n",
    "\n",
    "def compute_mgcx(X, Y, max_lag, is_fast = False):\n",
    "    mgcx = MGCX(max_lag = max_lag)\n",
    "    mgcx_statistic, metadata = mgcx.test_statistic(X, Y)\n",
    "    p_value, _ = mgcx.p_value(X, Y, is_fast = is_fast)\n",
    "    optimal_lag = metadata['optimal_lag']\n",
    "    optimal_scale = metadata['optimal_scale']\n",
    "    \n",
    "    print(\"MGCX test statistic:\", mgcx_statistic)\n",
    "    print(\"P Value:\", p_value)\n",
    "    print(\"Optimal Lag:\", optimal_lag)\n",
    "    print(\"Optimal Scale:\", optimal_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGCX test statistic: 0.19452035108660679\n",
      "P Value: 0.047619047619047616\n",
      "Optimal Lag: 0\n",
      "Optimal Scale: [34, 39]\n"
     ]
    }
   ],
   "source": [
    "# Simulate data. X and Y are n-by-1 matrices.\n",
    "n = 40\n",
    "X = np.random.normal(0.0, 1.0, n).reshape(n,1)\n",
    "Y = np.random.normal(0.0, 1.0, n).reshape(n,1)\n",
    "\n",
    "max_lag = 0\n",
    "compute_mgcx(X, Y, max_lag, is_fast = True)\n",
    "#compute_dcorrx(X, Y, max_lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: simulate data `X` and `Y` in the form of `n`-by-`p` and `n`-by-`q` matrices respectively, where `n` is the sample size.** In the following cells, we simulate different time series processes and estimate the power of the test at varying choices of sample size. Additionally, we compare against the Ljung-Box test of correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to simulate time series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indep_ar1(n, phi = 0.5, sigma2 = 1.0):\n",
    "    # X_t and Y_t are univarite AR(1) with phi = 0.5 for both.\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    X[0] = epsilons[0]\n",
    "    Y[0] = etas[0]\n",
    "    \n",
    "    # AR(1) process.\n",
    "    for t in range(1,n):\n",
    "        X[t] = phi*X[t-1] + epsilons[t]\n",
    "        Y[t] = phi*Y[t-1] + etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_dep_ar1(n, phi = 0.5, sigma2 = 1.0):\n",
    "    # X_t and Y_t are together a bivarite AR(1) with Phi = [0 0.5; 0.5 0].\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    X[0] = epsilons[0]\n",
    "    Y[0] = etas[0]\n",
    "    \n",
    "    for t in range(1,n):\n",
    "        X[t] = phi*Y[t-1] + epsilons[t]\n",
    "        Y[t] = phi*X[t-1] + etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlin_dep_lag_m(n, m = 1, phi_m = 1, sigma2 = 0.5):\n",
    "    # X_t and Y_t are together a bivarite nonlinear process.\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    for t in range(m):\n",
    "        Y[t] = etas[t]\n",
    "    \n",
    "    # AR(1) process.\n",
    "    for t in range(m,n):\n",
    "        X[t] = phi_m*epsilons[t]*Y[t-m]\n",
    "        Y[t] = etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples used to estimate the null distribution is: 100\n",
      "The p-value of fast MGCX is: 0.030000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "M = 0\n",
    "n = 100\n",
    "\n",
    "mgcx = MGCX(max_lag = M)\n",
    "X, Y = indep_ar1(n)\n",
    "\n",
    "test_stat, _ = mgcx.test_statistic(X, Y)\n",
    "p_value, metadata = mgcx.p_value(X, Y, is_fast = True)\n",
    "null_dist = metadata[\"null_distribution\"]\n",
    "print(\"The number of samples used to estimate the null distribution is: %d\" % len(null_dist))\n",
    "\n",
    "plt.hist(null_dist, align = 'mid', bins = 20)\n",
    "plt.axvline(test_stat, color='k', linestyle='dashed', linewidth=1)\n",
    "print(\"The p-value of fast MGCX is: %f\" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to run the Ljung-Box test of dependence using cross-correlations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LJUNG_BOX():\n",
    "    def __init__(self, max_lag = 0):\n",
    "        self.max_lag = max_lag\n",
    "        self.test_stat = None\n",
    "    def test_statistic(self, X, Y):\n",
    "        n = len(X)\n",
    "        test_statistic = 0\n",
    "        for j in range(self.max_lag+1):\n",
    "                lead_X = X[j:n]\n",
    "                lag_Y = Y[0:(n-j)]\n",
    "                test_statistic += ((np.corrcoef(lead_X,lag_Y)[1,0])**2 / (n-j))\n",
    "        self.test_stat = test_statistic*n*(n+2)\n",
    "        metadata = {}\n",
    "        return self.test_stat, metadata\n",
    "    def p_value(self, X, Y, replication_factor = 100):\n",
    "        test_stat, metadata = self.test_statistic(X, Y)\n",
    "        pval = 1 - chi2.cdf(test_stat, df = self.max_lag+4)\n",
    "        metadata = {}\n",
    "        return pval,  metadata\n",
    "    def get_test_statistic(self):\n",
    "        return self.test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Power as a function of `n` of the tests on each process.** Probability of correctly rejecting the null hypothesis that the time series are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_filename(s):\n",
    "    # Take title and format as filename.\n",
    "    filename = list(s.lower())\n",
    "    for i in range(len(filename)):\n",
    "        if filename[i] == \" \":\n",
    "            filename[i] = \"_\"\n",
    "    return(''.join(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_curve(sample_sizes, powers, alpha, title, savefig = True):\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"n\")\n",
    "    plt.ylabel(\"Rejection Probability\")\n",
    "    plt.ylim((-0.05, 1.05))\n",
    "    \n",
    "    plt.plot(sample_sizes, powers['fast-mgcx'], linestyle = '-', color = 'red')\n",
    "    # ax.legend(['DCorr-X', 'MGC-X'], loc = 'upper left', prop={'size': 12}) # Add back LB\n",
    "    ax.legend(['Fast-MGC-X'], loc = 'upper left', prop={'size': 12})\n",
    "    \n",
    "    ax.axhline(y=alpha, color = 'black', linestyle = '--')\n",
    "    # ax.axhline(y=1, color = 'black', linestyle = '--')\n",
    "    if savefig:\n",
    "        filename = \"power_curve_%s.png\" % format_filename(title)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of optimal lags for finite `n`.** The empirical distribution of the optimal lag returned by the test, visualized over the true Pearson's correlation of `X_t` and `Y_t` at each lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_lag_dist_stems(optimal_lags, true_correlations, title, color = 'red', savefig = True):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    # True correlations at various lags.\n",
    "    j = range(true_correlations.shape[0])\n",
    "    markerline, stemlines, baseline = plt.stem(j, true_correlations, '-k')\n",
    "    plt.setp(baseline, 'color', 'k', 'linewidth', 1)\n",
    "    plt.setp(markerline, 'markerfacecolor', 'k')\n",
    "    plt.xlabel('Lag j')\n",
    "    plt.ylabel(\"Corr(X(t), Y(t-j)) / Freq. of Optimal Lag Estimates\")\n",
    "    \n",
    "    # Optimal lab predictions.\n",
    "    weights = np.ones_like(optimal_lags)/float(len(optimal_lags))\n",
    "    plt.hist(optimal_lags, \n",
    "             bins = np.arange(len(true_correlations))-0.5, \n",
    "             weights = weights, \n",
    "             align = 'mid',\n",
    "             edgecolor ='black',\n",
    "             color = color)\n",
    "    \n",
    "    filename = \"optimal_lag_dist_stems_%s.png\" % format_filename(title)\n",
    "    if savefig:\n",
    "        plt.title(title)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_lag_dist(optimal_lags, title, color = 'red', savefig = True):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    plt.xlabel('Lag j')\n",
    "    plt.ylabel(\"Freq. of Optimal Lag Estimates\")\n",
    "    \n",
    "    # Optimal lab predictions.\n",
    "    weights = np.ones_like(optimal_lags)/float(len(optimal_lags))\n",
    "    plt.hist(optimal_lags, \n",
    "             bins = np.arange(len(true_correlations))-0.5, \n",
    "             weights = weights, \n",
    "             align = 'mid',\n",
    "             edgecolor ='black',\n",
    "             color = color)\n",
    "    \n",
    "    filename = \"optimal_lag_dist_%s.png\" % format_filename(title)\n",
    "    if savefig:\n",
    "        plt.title(title)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full experiment, simulating the above time series, and counting the rejections and optimal lag detections by each test (as a function of `n`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all time series simulations.\n",
    "processes = {\n",
    "    'indep_ar1'  : { 'simulate': indep_ar1,  'name': \"Independent AR(1)\"},\n",
    "    'lin_dep_ar1': { 'simulate': lin_dep_ar1,  'name': \"Correlated AR(1)\"},\n",
    "    'nonlin_dep_lag_m' : { 'simulate': nonlin_dep_lag_m,  'name': \"Nonlinearly Dependent at Lag 1\"}, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: parameters.\n",
    "sample_sizes  = range(200,220,10)\n",
    "num_sims      = 30\n",
    "num_bootstrap = 100\n",
    "alpha         = 0.05\n",
    "maxlag        = 1\n",
    "compute_pval  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating power at n = 200..............................\n",
      "Estimating power at n = 210..............................\n"
     ]
    }
   ],
   "source": [
    "# Initialize objects and holders.\n",
    "mgcx      = MGCX(max_lag = maxlag)\n",
    "powers    = {'fast-mgcx': np.zeros(len(sample_sizes))}\n",
    "\n",
    "# Run experiments.\n",
    "for p in ['indep_ar1']:\n",
    "    process = processes[p]\n",
    "    simulate = process['simulate']\n",
    "    for i in range(len(sample_sizes)):\n",
    "        rejects  = {'fast-mgcx': 0}\n",
    "        n = sample_sizes[i]\n",
    "        print(\"Estimating power at n =\", str(n), end = \"\")\n",
    "        \n",
    "        # Simulate time series and count rejections.\n",
    "        for t in range(num_sims):\n",
    "            print('.', end='')\n",
    "            X, Y = simulate(n)\n",
    "                \n",
    "            # MGC-X Block + Subsampling\n",
    "            p_value, _ = mgcx.p_value(X, Y, replication_factor = num_bootstrap, is_fast = True)\n",
    "            if (p_value < alpha): rejects['fast-mgcx'] += 1\n",
    "        \n",
    "        powers['fast-mgcx'][i] = rejects['fast-mgcx'] / num_sims\n",
    "        print(\"\")\n",
    "        \n",
    "    # Display power estimates.\n",
    "    fast_mgcx_powers = np.vstack((np.array(sample_sizes), powers['fast-mgcx'])).T\n",
    "    np.savetxt(\"fast-mgcx-\" + p + \".csv\", fast_mgcx_powers, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['indep_ar1']:\n",
    "    fast_mgcx_powers = np.genfromtxt('fast-mgcx-' + p + '.csv', delimiter=',')\n",
    "  \n",
    "    process = processes[p]\n",
    "    sample_sizes = fast_mgcx_powers[:, 0]\n",
    "    powers = {'fast-mgcx': fast_mgcx_powers[:, 1]}\n",
    "    power_curve(sample_sizes, powers, alpha, process['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: parameters.\n",
    "sample_sizes  = range(40,170,20)\n",
    "num_sims      = 40\n",
    "num_bootstrap = 100\n",
    "alpha         = 0.05\n",
    "maxlag        = 1\n",
    "compute_pval  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize objects and holders.\n",
    "dcorrx  = DCorrX(max_lag = maxlag)\n",
    "mgcx    = MGCX(max_lag = maxlag)\n",
    "lb      = LJUNG_BOX(max_lag = maxlag)\n",
    "tests   = {'dcorrx': dcorrx, 'mgcx': mgcx, 'lb': lb}\n",
    "powers  = {'dcorrx': np.zeros(len(sample_sizes)), \n",
    "           'mgcx': np.zeros(len(sample_sizes)), \n",
    "           'lb': np.zeros(len(sample_sizes))}\n",
    "lag_probs = {'dcorrx': np.zeros(len(sample_sizes)), \n",
    "             'mgcx': np.zeros(len(sample_sizes))}\n",
    "\n",
    "# Run experiments.\n",
    "for p in ['nonlin_dep_lag_m']:\n",
    "    process = processes[p]\n",
    "    simulate = process['simulate']\n",
    "    for i in range(len(sample_sizes)):\n",
    "        rejects  = {'dcorrx': 0.0, 'mgcx': 0.0, 'lb': 0.0}\n",
    "        opt_lags = {'dcorrx': np.zeros(num_sims), 'mgcx': np.zeros(num_sims)}\n",
    "        n = sample_sizes[i]\n",
    "        print(\"Estimating power/lag detection prob. at n =\", str(n), end = \"\")\n",
    "        \n",
    "        # Simulate time series and count rejections.\n",
    "        for t in range(num_sims):\n",
    "            print('.', end='')\n",
    "            X, Y = simulate(n)\n",
    "            \n",
    "            for r in ['mgcx']:\n",
    "                test = tests[r]\n",
    "                if r is not 'lb':\n",
    "                    test_statistic, metadata = test.test_statistic(X, Y)\n",
    "                    detects = opt_lags[r]\n",
    "                    detects[t] = metadata['optimal_lag']\n",
    "                if compute_pval:\n",
    "                    p_value, _ = test.p_value(X, Y, replication_factor = num_bootstrap, is_fast = True)\n",
    "                    if (p_value < alpha): rejects[r] += 1\n",
    "        for r in ['dcorrx', 'mgcx']:\n",
    "            power = powers[r]\n",
    "            power[i] = rejects[r]/num_sims\n",
    "            if r is not 'lb':\n",
    "                lag_prob = lag_probs[r]\n",
    "                lag_prob[i] = np.count_nonzero(opt_lags[r] == process['true_lag'])/num_sims\n",
    "        print(\"\")\n",
    "        \n",
    "    # Display power estimates and probility of detecting the correct lag.\n",
    "    dcorrx_powers = np.vstack((np.array(sample_sizes), powers['dcorrx'])).T\n",
    "    mgcx_powers = np.vstack((np.array(sample_sizes), powers['mgcx'])).T\n",
    "    np.savetxt(\"dcorrx_\" + p + \".csv\", dcorrx_powers, delimiter=',')\n",
    "    np.savetxt(\"mgcx_\" + p + \".csv\", mgcx_powers, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['nonlin_dep_lag_m']:\n",
    "    mgcx_powers = np.genfromtxt('mgcx_' + p + '.csv', delimiter=',')\n",
    "  \n",
    "    process = processes[p]\n",
    "    sample_sizes = mgcx_powers[:, 0]\n",
    "    powers = {'dcorrx': dcorrx_powers[:, 1], \n",
    "              'mgcx': mgcx_powers[:, 1]}\n",
    "    power_curve(sample_sizes, powers, alpha, process['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing the distribution of optimal lags returned by the tests.** We see how that the optimal lags returned by the test corresponds with the true dependence structure of the simulated time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_dep_ar3(n, phi_1 = 0.5, phi_3 = 0.5, sigma2 = 1.0):\n",
    "    # X_t and Y_t are together a bivarite AR(3).\n",
    "    # Innovations follow N(0, sigma2).\n",
    "    \n",
    "    # Innovations.\n",
    "    epsilons = np.random.normal(0.0, sigma2, n)\n",
    "    etas = np.random.normal(0.0, sigma2, n)\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    Y = np.zeros(n)\n",
    "    for s in range(3):\n",
    "        X[s] = epsilons[s]\n",
    "        Y[s] = etas[s]\n",
    "    \n",
    "    # AR(1) process.\n",
    "    for t in range(3,n):\n",
    "        X[t] = phi_1*Y[t-1] + phi_3*Y[t-3] + epsilons[t]\n",
    "        Y[t] = phi_1*X[t-1] + phi_3*X[t-3] + etas[t]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlated AR(3)\n",
    "phi_1 = 0.1\n",
    "phi_3 = 0.8\n",
    "sigma2 = 1.0\n",
    "M = 10\n",
    "num_sims = 100\n",
    "\n",
    "# Determine true correlations.\n",
    "rho_XY = np.zeros(M+1)\n",
    "rho_X = np.zeros(M+1)\n",
    "rho_X[0] = 1\n",
    "rho_XY[1] = phi_1 / (1 - phi_3*(phi_1 + phi_3))\n",
    "rho_X[2] = (phi_1 + phi_3)*rho_XY[1]\n",
    "for j in range(3, M+1):\n",
    "    if j%2:\n",
    "        rho_XY[j] = phi_1*rho_X[j-1] + phi_3*rho_X[j-3]\n",
    "    else:\n",
    "        rho_X[j] = phi_1*rho_XY[j-1] + phi_3*rho_XY[j-3]\n",
    "\n",
    "dcorrx = DCorrX(max_lag = M)\n",
    "mgcx = MGCX(max_lag = M)\n",
    "true_correlations = rho_XY\n",
    "optimal_lags_dcorrx = np.zeros(num_sims)\n",
    "optimal_lags_mgcx = np.zeros(num_sims)\n",
    "\n",
    "# Run experiments.\n",
    "for n in [15, 30, 60]:\n",
    "    for t in range(num_sims):\n",
    "        X, Y = lin_dep_ar3(n, phi_1 = phi_1, phi_3 = phi_3, sigma2 = sigma2)\n",
    "        test_statistic, metadata = dcorrx.test_statistic(X, Y)\n",
    "        optimal_lags_dcorrx[t] = metadata['optimal_lag']\n",
    "        test_statistic, metadata = mgcx.test_statistic(X, Y)\n",
    "        optimal_lags_mgcx[t] = metadata['optimal_lag']\n",
    "    title_dcorrx = \"Dcorr-X, Crosscorrelated AR(3), n = %d\" % n\n",
    "    title_mgcx = \"MGC-X, Crosscorrelated AR(3), n = %d\" % n\n",
    "    opt_lag_dist_stems(optimal_lags_dcorrx, true_correlations, title = title_dcorrx, color = 'blue')\n",
    "    opt_lag_dist_stems(optimal_lags_mgcx, true_correlations, title = title_mgcx, color = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate a nonlinear process, estimate the Cross Distance Correlation Function, and show that the optimal lag is correct for large n.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2 = 1.0\n",
    "M = 10\n",
    "m = 3\n",
    "num_sims = 100\n",
    "\n",
    "dcorrx = DCorrX(max_lag = M)\n",
    "mgcx = MGCX(max_lag = M)\n",
    "optimal_lags_dcorrx = np.zeros(num_sims)\n",
    "optimal_lags_mgcx = np.zeros(num_sims)\n",
    "\n",
    "# Run experiments.\n",
    "for n in [15, 30, 60]:\n",
    "    for t in range(num_sims):\n",
    "        X, Y = nonlin_dep_lag_m(n, m, phi_m = 0.8, sigma2 = 1.0)\n",
    "        test_statistic, metadata = dcorrx.test_statistic(X, Y)\n",
    "        optimal_lags_dcorrx[t] = metadata['optimal_lag']\n",
    "        test_statistic, metadata = mgcx.test_statistic(X, Y)\n",
    "        optimal_lags_mgcx[t] = metadata['optimal_lag']\n",
    "    title_dcorrx = \"Dcorr-X, Nonlinearly Dependent at Lag 3, n = %d\" % n\n",
    "    title_mgcx = \"MGC-X, Nonlinearly Dependent at Lag 3, n = %d\" % n\n",
    "    opt_lag_dist(optimal_lags_dcorrx, title = title_dcorrx, color = 'blue')\n",
    "    opt_lag_dist(optimal_lags_mgcx, title = title_mgcx, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
